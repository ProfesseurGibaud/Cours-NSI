{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Guidé : WebScrapping\n",
    "## I) Le WebScrapping dans la vraie vie\n",
    "\n",
    "Le WebScrapping est une activité très utilisé dans l’industrie informatique. En effet\n",
    "c’est un outil très efficace pour récolter des données sur Internet et pouvoir les traiter.\n",
    "Cependant est ce que c’est légal ?\n",
    "\n",
    "\n",
    "Extrait de <i>L’usine Digitale</i>\n",
    "\n",
    "La pratique du web scraping pourrait être considérée comme un \"vol de données\"\n",
    "(atteinte au STAD) en s’appuyant sur l’article 323-3 du Code pénal qui énonce :\n",
    "\"Le fait d’introduire frauduleusement des données dans un système de traitement\n",
    "automatisé, d’extraire, de détenir, de reproduire, de transmettre, de supprimer ou de\n",
    "modifier frauduleusement les données qu’il contient est puni de cinq ans d’emprisonnement et de 150 000 € d’amende. Lorsque cette infraction a été commise à l’encontre d’un système de traitement automatisé de données à caractère personnel mis\n",
    "en oeuvre par l’Etat, la peine est portée à sept ans d’emprisonnement et à 300 000\n",
    "€ d’amende.\" Il conviendrait toutefois de caractériser l’intention frauduleuse du web\n",
    "scraping.\n",
    "On peut également considérer qu’il s’agit d’un acte de concurrence déloyale ou\n",
    "d’une pratique de parasitisme, la personne recourant au web scraping n’ayant pas effectué les mêmes efforts (en termes de communication, d’investissements techniques,\n",
    "etc.) que le teneur du site pour collecter ces données.\n",
    "En outre, ce point se double d’exigences impératives en matière de protection des\n",
    "données à caractère personnel des utilisateurs à l’heure où le RGPD constitue une\n",
    "donne incontournable dans la stratégie des entreprises connectées. Il met en exergue\n",
    "la nécessité d’une gouvernance des données à caractère personnel (tant organisationnelle que juridique ou technique)...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<i> Le mot du professeur </i>\n",
    "\n",
    "Pour ne pas tomber dans l'illégalité dans le webscrapping.\n",
    "* Ne publiez pas en ligne les informations que vous avez récupérer avec le webscrapping.\n",
    "* Limitez au maximum le nombre de connexion au site (1 connexion maximum par page), comme vous le feriez en naviguant à la main. Les connexions sont faites grâce au module requests. <b>NE METTEZ JAMAIS <code>requests</code> DANS UNE BOUCLE</b>\n",
    "\n",
    "Si les données sont en licence libre, alors vous avez le droit d’y accéder librement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II) Installation des prerequis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taper dans le terminal (en bas ou dans Terminal -> ouvrir Nouveau Terminal)\n",
    "```\n",
    "pip install --user --trusted-host Pypi.org --proxy=10.0.0.1:3128 beautifulsoup4\n",
    "```\n",
    "\n",
    "```\n",
    "pip install --user --trusted-host Pypi.org --proxy=10.0.0.1:3128 requests\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette commande permet d’installer la librairie beautifulsoup4 qui permet à partir\n",
    "du texte d’une page html d’obtenir un objet dans lequel on pourra naviguer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III) Initialisation \n",
    "\n",
    "On va charger les librairies dont on aura besoin : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les connexions sortantes et entrantes du lycée passe par un \"tunnel\" appelé proxy. On va préparer une variable (de quel type) avec les coordonnées de ce tunnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = {\"http\":\"10.0.0.1:3128\",\"https\":\"10.0.0.1:3128\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va aller chercher une liste d'animé sur le site suivant : https://www.senscritique.com/liste/liste_complete_anime/478051"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>Exercice</strong>\n",
    "Faire une variable <code>url</code> qui sera un string et qui aura pour valeur l'url précédente.\n",
    "</div>\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ...\n",
    "url = \"https://www.senscritique.com/liste/liste_complete_anime/478051\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV) Navigation sur le site et recherche des points clés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Connectez vous avec votre navigateur à https://www.senscritique.com/liste/liste_complete_anime/478051"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Inspecter le titre du premier anime que vous voyez. Quelle est sa balise et si il a une classe quelle est sa classe (et ses autres attributs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse : .........................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Chercher en remontant l'inspecteur de code la plus petite balise contenant tous les animes. Vérifier que sa balise est un div et que sa classe est ```\"List__WrapperLists-sc-13autox-3 bgPFiI\"```. Que signifie List__Wrapper ? Est ce que cela a du sens que sa classe est List__Wrapper ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse : ................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Supposer que vous pouvez tout extraire. Proposez une méthode pour pouvoir extraire tous les animes de cette page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse : ......................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V) Automatisation de la collecte d'information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. On se connecte au site via python en utilisant le package ```requests```. On utilise la fonction ```get``` du package ```requests``` avec les arguments ```url``` pour faire une requête GET à l'url et ```proxies``` pour préciser le tunnel de connexion (c'est un argument facultatif mais au lycée il faut absolument le mettre).\n",
    "\n",
    "Si on voulait faire un POST quelle fonction aurait-on utilisé et quels auraient été les arguments ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url,proxies = proxies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Afficher le contenu de la réponse ```response```. Le contenu est dans ```response.content```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Vous avez vu c'est moche et illisible. Pour le rendre lisible, on va le découper en suivant les balises html. Cette activité s'appeler \"parser\" le texte. L'outil en python qui permet de parser des pages html est ```BeautifulSoup``` du package ```bs4```. On va donc appeler la classe ```BeautifulSoup``` avec comme argument le contenu de la page ```response.content``` et ```\"html.parser``` pour dire qu'on veut parser du html. \n",
    "\n",
    "Compléter la cellule pour afficher ```soup```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maintenant on va chercher nos animes. On a pas fait tout ça pour rien :) On va pas les chercher, on va les trouver tous avec la méthode ```find_all```. Ce dernier prend pour argument :\n",
    "   * un argument obligatoire : la balise de ce que l'on cherche.\n",
    "   * un argument facultatif : les attributs la balise que l'on cherche.\n",
    " \n",
    "  Recopier dans une variable ```classe``` du type ```string``` le contenu de l'attribut ```class``` de la balise du IV.3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe = ...\n",
    "classe = \"List__WrapperLists-sc-13autox-3 bgPFiI\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme l'attribut ```class``` est en fait une liste on va transformer le string en liste grace à la méthode ```split```. La méthode ```.split(\" \")``` prendra le string et le séparera tous les espaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_classe = classe.split(\" \")\n",
    "liste_classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement notre recherche donne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_div = soup.find_all(\"div\",{\"class\":classe.split(\" \")})\n",
    "liste_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Regardons la longueur de ```liste_div```. On aimerait avoir une longueur de 1 pour être sûr de prendre le bon élément. Chercher la longueur de ```liste```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Quelle est la longueur de ```liste_div``` ? \n",
    "* Est ce que c'est ce que vous voulez ? \n",
    "* Faite une variable ```tag_liste``` contenant l'unique élément de ```liste_div```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse : ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_liste = ...\n",
    "tag_liste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Maintenant que l'on a la liste de tous les mangas on va chercher les informations de chaque manga. Chercher sur le navigateur le plus petit élément contenant toutes les informations sur un seul manga. Donner \n",
    "   * sa balise\n",
    "   * ses attributs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balise : ...\n",
    "\n",
    "Attribut : ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Maintenant on refait l'étape 4 (```find_all```) avec la balise précédente. Ecrivez votre code en dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "liste_tag_manga = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Quelle est la longueur de votre ```find_all``` ? Est ce normal (comptez combien il y a de manga sur une page et comparez le à la longueur du ```find_all```)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse : ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Maintenant il va falloir rentrer dans le détail. On va procéder en 3 étapes\n",
    "   *  Exploration. On va prendre un tag en particulier et on va chercher où sont les informations précisément.\n",
    "   *  Automatisation. On va faire une fonction qui prend en entrée un ```tag``` et qui renvoie les informations qui nous interesse.\n",
    "   *  Récupération des informations. On va faire une boucle sur ```liste_tag_manga``` qui applique la fonction à chaque ```tag``` de la liste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 9. 1. Faites une variable ```tag``` avec le premier élément de ```liste_tag_manga```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = liste_tag_manga[0]\n",
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 2. Dans quelle balise et avec quel attribut est le titre du manga (Attention ne regardait pas que la classe)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse : ........"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 3. Utiliser la fonction ```find_all``` pour trouver la balise avec le titre. Extraire l'unique élément de ce ```find_all```. Affecter le à une variable ```tag_titre```. Le titre est dans l'attribut ```texte```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "tag_titre = tag.find_all(\"a\",{\"data-testid\":\"product-title\"})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titre = tag_titre.text\n",
    "titre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 4. De la même façon, trouvez la durée des épisodes, la date de première diffusion, le nombre de saisons et le genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 5. Faites 5 fonctions qui prennent en argument un ```tag``` et qui renvoie respectivement \n",
    "    * le titre\n",
    "    * la durée des épisodes\n",
    "    * la date de première diffusion\n",
    "    * le nombre de saisons\n",
    "    * le genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 6. Appliquez ces fonctions à tous les ```tag``` de ```liste_tag_manga```. Mettez chaque résultat dans une liste différente : ```liste_titre```, ```liste_duree```, ```liste_release```, ```liste_number_season```, ```liste_genre```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 7. La commande suivante permet de faire une table avec tous les animes de façon rangée. Pour la faire on utilise la package pandas, qui gère les tables, appelés ```DataFrame```. La donnée de base est un dictionnaire où les clés sont les noms des colonnes que l'on veut pour notre tableau et les valeurs sont les listes de ce que l'on veut avoir. Mieux vaut comprendre sur un exemple. Le voici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframe_manga = pd.DataFrame({\n",
    "    \"Titre\":liste_titre,\n",
    "    \"Durée\":liste_duree,\n",
    "    \"Diffusion\":liste_release,\n",
    "    \"Nombre de Saisons\":liste_number_season,\n",
    "    \"Genre\":liste_genre\n",
    "    })\n",
    "dataframe_manga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Faire une fonction qui à une ```liste_titre```, ```liste_duree```, ```liste_release```, ```liste_number_season```, ```liste_genre``` associe une liste de dictionnaire de la forme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"Titre\":titre_du_manga, \"Durée\":duree_du_manga,\"Date de diffusion\":release_manga,\"Nombre de saisons\":season_number,\"Genre\":genre}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devoir Maison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur le site, il y a 8 pages d'anime. Nous avons analisé une page d'anime. Faite un ```Dataframe``` comme dans le 9.7. mais avec tous les animes du site."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
